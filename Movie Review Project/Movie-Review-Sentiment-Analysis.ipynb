{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Review Sentiment Analyisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jakub/Python_Projects/NLP/Movie-Review-Project'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>rotten_tomatoes_link</th>\n",
       "      <th>critic_name</th>\n",
       "      <th>top_critic</th>\n",
       "      <th>publisher_name</th>\n",
       "      <th>review_type</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_content</th>\n",
       "      <th>threshold</th>\n",
       "      <th>...</th>\n",
       "      <th>tomatometer_status</th>\n",
       "      <th>tomatometer_rating</th>\n",
       "      <th>tomatometer_count</th>\n",
       "      <th>audience_status</th>\n",
       "      <th>audience_rating</th>\n",
       "      <th>audience_count</th>\n",
       "      <th>tomatometer_top_critics_count</th>\n",
       "      <th>tomatometer_fresh_critics_count</th>\n",
       "      <th>tomatometer_rotten_critics_count</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Kurt Loder</td>\n",
       "      <td>False</td>\n",
       "      <td>MTV</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>Sadly worthy of its dumping into the cinematic...</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>49.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>Spilled</td>\n",
       "      <td>53.0</td>\n",
       "      <td>254421.0</td>\n",
       "      <td>43</td>\n",
       "      <td>73</td>\n",
       "      <td>76</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Christopher Tookey</td>\n",
       "      <td>False</td>\n",
       "      <td>Daily Mail (UK)</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010-02-16</td>\n",
       "      <td>Maybe if you're aged between eight and 12, or ...</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>49.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>Spilled</td>\n",
       "      <td>53.0</td>\n",
       "      <td>254421.0</td>\n",
       "      <td>43</td>\n",
       "      <td>73</td>\n",
       "      <td>76</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Tim Robey</td>\n",
       "      <td>True</td>\n",
       "      <td>Daily Telegraph (UK)</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010-02-16</td>\n",
       "      <td>A slab of market research in search of an actu...</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>49.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>Spilled</td>\n",
       "      <td>53.0</td>\n",
       "      <td>254421.0</td>\n",
       "      <td>43</td>\n",
       "      <td>73</td>\n",
       "      <td>76</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Anthony Quinn</td>\n",
       "      <td>True</td>\n",
       "      <td>Independent (UK)</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010-02-16</td>\n",
       "      <td>If they'd played it for laughs it might just h...</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>49.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>Spilled</td>\n",
       "      <td>53.0</td>\n",
       "      <td>254421.0</td>\n",
       "      <td>43</td>\n",
       "      <td>73</td>\n",
       "      <td>76</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Derek Malcolm</td>\n",
       "      <td>True</td>\n",
       "      <td>London Evening Standard</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010-02-16</td>\n",
       "      <td>This ineffably wooden Chris Columbus adaptatio...</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>49.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>Spilled</td>\n",
       "      <td>53.0</td>\n",
       "      <td>254421.0</td>\n",
       "      <td>43</td>\n",
       "      <td>73</td>\n",
       "      <td>76</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 rotten_tomatoes_link         critic_name  top_critic  \\\n",
       "0          23            m/0814255          Kurt Loder       False   \n",
       "1          44            m/0814255  Christopher Tookey       False   \n",
       "2          50            m/0814255           Tim Robey        True   \n",
       "3          58            m/0814255       Anthony Quinn        True   \n",
       "4          61            m/0814255       Derek Malcolm        True   \n",
       "\n",
       "            publisher_name review_type  review_score review_date  \\\n",
       "0                      MTV      Rotten           1.0  2010-02-12   \n",
       "1          Daily Mail (UK)      Rotten           1.0  2010-02-16   \n",
       "2     Daily Telegraph (UK)      Rotten           1.0  2010-02-16   \n",
       "3         Independent (UK)      Rotten           1.0  2010-02-16   \n",
       "4  London Evening Standard      Rotten           1.0  2010-02-16   \n",
       "\n",
       "                                      review_content threshold  ...  \\\n",
       "0  Sadly worthy of its dumping into the cinematic...         5  ...   \n",
       "1  Maybe if you're aged between eight and 12, or ...         5  ...   \n",
       "2  A slab of market research in search of an actu...         5  ...   \n",
       "3  If they'd played it for laughs it might just h...         5  ...   \n",
       "4  This ineffably wooden Chris Columbus adaptatio...         5  ...   \n",
       "\n",
       "  tomatometer_status tomatometer_rating tomatometer_count audience_status  \\\n",
       "0             Rotten               49.0             149.0         Spilled   \n",
       "1             Rotten               49.0             149.0         Spilled   \n",
       "2             Rotten               49.0             149.0         Spilled   \n",
       "3             Rotten               49.0             149.0         Spilled   \n",
       "4             Rotten               49.0             149.0         Spilled   \n",
       "\n",
       "  audience_rating audience_count tomatometer_top_critics_count  \\\n",
       "0            53.0       254421.0                            43   \n",
       "1            53.0       254421.0                            43   \n",
       "2            53.0       254421.0                            43   \n",
       "3            53.0       254421.0                            43   \n",
       "4            53.0       254421.0                            43   \n",
       "\n",
       "  tomatometer_fresh_critics_count tomatometer_rotten_critics_count sentiment  \n",
       "0                              73                               76  Negative  \n",
       "1                              73                               76  Negative  \n",
       "2                              73                               76  Negative  \n",
       "3                              73                               76  Negative  \n",
       "4                              73                               76  Negative  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open the recently created rotten tomatoes dataset for analysis\n",
    "df = pd.read_csv('Rotten_Tomatoes_Dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'rotten_tomatoes_link', 'critic_name', 'top_critic',\n",
       "       'publisher_name', 'review_type', 'review_score', 'review_date',\n",
       "       'review_content', 'threshold', 'movie_title', 'movie_info',\n",
       "       'critics_consensus', 'content_rating', 'genres', 'directors', 'authors',\n",
       "       'actors', 'original_release_date', 'streaming_release_date', 'runtime',\n",
       "       'production_company', 'tomatometer_status', 'tomatometer_rating',\n",
       "       'tomatometer_count', 'audience_status', 'audience_rating',\n",
       "       'audience_count', 'tomatometer_top_critics_count',\n",
       "       'tomatometer_fresh_critics_count', 'tomatometer_rotten_critics_count',\n",
       "       'sentiment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review_score</th>\n",
       "      <th>runtime</th>\n",
       "      <th>tomatometer_rating</th>\n",
       "      <th>tomatometer_count</th>\n",
       "      <th>audience_rating</th>\n",
       "      <th>audience_count</th>\n",
       "      <th>tomatometer_top_critics_count</th>\n",
       "      <th>tomatometer_fresh_critics_count</th>\n",
       "      <th>tomatometer_rotten_critics_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>59037.000000</td>\n",
       "      <td>59037.000000</td>\n",
       "      <td>58674.000000</td>\n",
       "      <td>58969.000000</td>\n",
       "      <td>58969.000000</td>\n",
       "      <td>58926.000000</td>\n",
       "      <td>5.891000e+04</td>\n",
       "      <td>59037.000000</td>\n",
       "      <td>59037.000000</td>\n",
       "      <td>59037.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>212619.218643</td>\n",
       "      <td>3.737063</td>\n",
       "      <td>110.886594</td>\n",
       "      <td>68.910156</td>\n",
       "      <td>157.596771</td>\n",
       "      <td>68.852238</td>\n",
       "      <td>5.334537e+05</td>\n",
       "      <td>33.383709</td>\n",
       "      <td>118.964886</td>\n",
       "      <td>38.575791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>125983.044495</td>\n",
       "      <td>1.859246</td>\n",
       "      <td>22.145725</td>\n",
       "      <td>31.308442</td>\n",
       "      <td>113.896312</td>\n",
       "      <td>21.240769</td>\n",
       "      <td>3.607354e+06</td>\n",
       "      <td>17.996908</td>\n",
       "      <td>111.227056</td>\n",
       "      <td>43.367737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>102126.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>7.652000e+03</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>214224.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>3.641800e+04</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>321294.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>1.415010e+05</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>431552.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>574.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>3.579764e+07</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>497.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0  review_score       runtime  tomatometer_rating  \\\n",
       "count   59037.000000  59037.000000  58674.000000        58969.000000   \n",
       "mean   212619.218643      3.737063    110.886594           68.910156   \n",
       "std    125983.044495      1.859246     22.145725           31.308442   \n",
       "min        23.000000      1.000000      5.000000            0.000000   \n",
       "25%    102126.000000      1.000000     95.000000           43.000000   \n",
       "50%    214224.000000      5.000000    107.000000           85.000000   \n",
       "75%    321294.000000      5.000000    122.000000           93.000000   \n",
       "max    431552.000000      5.000000    266.000000          100.000000   \n",
       "\n",
       "       tomatometer_count  audience_rating  audience_count  \\\n",
       "count       58969.000000     58926.000000    5.891000e+04   \n",
       "mean          157.596771        68.852238    5.334537e+05   \n",
       "std           113.896312        21.240769    3.607354e+06   \n",
       "min             5.000000         0.000000    5.000000e+00   \n",
       "25%            64.000000        53.000000    7.652000e+03   \n",
       "50%           135.000000        76.000000    3.641800e+04   \n",
       "75%           226.000000        86.000000    1.415010e+05   \n",
       "max           574.000000       100.000000    3.579764e+07   \n",
       "\n",
       "       tomatometer_top_critics_count  tomatometer_fresh_critics_count  \\\n",
       "count                   59037.000000                     59037.000000   \n",
       "mean                       33.383709                       118.964886   \n",
       "std                        17.996908                       111.227056   \n",
       "min                         0.000000                         0.000000   \n",
       "25%                        17.000000                        29.000000   \n",
       "50%                        36.000000                        81.000000   \n",
       "75%                        48.000000                       183.000000   \n",
       "max                        69.000000                       497.000000   \n",
       "\n",
       "       tomatometer_rotten_critics_count  \n",
       "count                      59037.000000  \n",
       "mean                          38.575791  \n",
       "std                           43.367737  \n",
       "min                            0.000000  \n",
       "25%                            7.000000  \n",
       "50%                           22.000000  \n",
       "75%                           55.000000  \n",
       "max                          303.000000  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['movie_title','genres','review_content','sentiment']] # select only the columns we want to work with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "      <th>genres</th>\n",
       "      <th>review_content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Percy Jackson &amp; the Olympians: The Lightning T...</td>\n",
       "      <td>Action &amp; Adventure, Comedy, Drama, Science Fic...</td>\n",
       "      <td>Sadly worthy of its dumping into the cinematic...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Percy Jackson &amp; the Olympians: The Lightning T...</td>\n",
       "      <td>Action &amp; Adventure, Comedy, Drama, Science Fic...</td>\n",
       "      <td>Maybe if you're aged between eight and 12, or ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Percy Jackson &amp; the Olympians: The Lightning T...</td>\n",
       "      <td>Action &amp; Adventure, Comedy, Drama, Science Fic...</td>\n",
       "      <td>A slab of market research in search of an actu...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Percy Jackson &amp; the Olympians: The Lightning T...</td>\n",
       "      <td>Action &amp; Adventure, Comedy, Drama, Science Fic...</td>\n",
       "      <td>If they'd played it for laughs it might just h...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Percy Jackson &amp; the Olympians: The Lightning T...</td>\n",
       "      <td>Action &amp; Adventure, Comedy, Drama, Science Fic...</td>\n",
       "      <td>This ineffably wooden Chris Columbus adaptatio...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         movie_title  \\\n",
       "0  Percy Jackson & the Olympians: The Lightning T...   \n",
       "1  Percy Jackson & the Olympians: The Lightning T...   \n",
       "2  Percy Jackson & the Olympians: The Lightning T...   \n",
       "3  Percy Jackson & the Olympians: The Lightning T...   \n",
       "4  Percy Jackson & the Olympians: The Lightning T...   \n",
       "\n",
       "                                              genres  \\\n",
       "0  Action & Adventure, Comedy, Drama, Science Fic...   \n",
       "1  Action & Adventure, Comedy, Drama, Science Fic...   \n",
       "2  Action & Adventure, Comedy, Drama, Science Fic...   \n",
       "3  Action & Adventure, Comedy, Drama, Science Fic...   \n",
       "4  Action & Adventure, Comedy, Drama, Science Fic...   \n",
       "\n",
       "                                      review_content sentiment  \n",
       "0  Sadly worthy of its dumping into the cinematic...  Negative  \n",
       "1  Maybe if you're aged between eight and 12, or ...  Negative  \n",
       "2  A slab of market research in search of an actu...  Negative  \n",
       "3  If they'd played it for laughs it might just h...  Negative  \n",
       "4  This ineffably wooden Chris Columbus adaptatio...  Negative  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the review column \n",
    "def clean_text(text):\n",
    "    \"\"\" \n",
    "    Change words to lower case, remove any punctuation and stop words \n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub('[!|.|,|?|!|-|+]','',text)\n",
    "    text = re.sub('\\d','',text)\n",
    "    text = ' '.join([word for word in text.split() if word not in (stopwords.words('english'))])\n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text('Hello 123?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = lambda x: clean_text(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_content'] = df['review_content'].apply(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "      <th>genres</th>\n",
       "      <th>review_content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Percy Jackson &amp; the Olympians: The Lightning T...</td>\n",
       "      <td>Action &amp; Adventure, Comedy, Drama, Science Fic...</td>\n",
       "      <td>sadly worthy dumping cinematic boneyard wintry...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Percy Jackson &amp; the Olympians: The Lightning T...</td>\n",
       "      <td>Action &amp; Adventure, Comedy, Drama, Science Fic...</td>\n",
       "      <td>maybe aged eight exceptionally dim-witted may ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Percy Jackson &amp; the Olympians: The Lightning T...</td>\n",
       "      <td>Action &amp; Adventure, Comedy, Drama, Science Fic...</td>\n",
       "      <td>slab market research search actual movie</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Percy Jackson &amp; the Olympians: The Lightning T...</td>\n",
       "      <td>Action &amp; Adventure, Comedy, Drama, Science Fic...</td>\n",
       "      <td>they'd played laughs might worked fact earnest...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Percy Jackson &amp; the Olympians: The Lightning T...</td>\n",
       "      <td>Action &amp; Adventure, Comedy, Drama, Science Fic...</td>\n",
       "      <td>ineffably wooden chris columbus adaptation aut...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         movie_title  \\\n",
       "0  Percy Jackson & the Olympians: The Lightning T...   \n",
       "1  Percy Jackson & the Olympians: The Lightning T...   \n",
       "2  Percy Jackson & the Olympians: The Lightning T...   \n",
       "3  Percy Jackson & the Olympians: The Lightning T...   \n",
       "4  Percy Jackson & the Olympians: The Lightning T...   \n",
       "\n",
       "                                              genres  \\\n",
       "0  Action & Adventure, Comedy, Drama, Science Fic...   \n",
       "1  Action & Adventure, Comedy, Drama, Science Fic...   \n",
       "2  Action & Adventure, Comedy, Drama, Science Fic...   \n",
       "3  Action & Adventure, Comedy, Drama, Science Fic...   \n",
       "4  Action & Adventure, Comedy, Drama, Science Fic...   \n",
       "\n",
       "                                      review_content sentiment  \n",
       "0  sadly worthy dumping cinematic boneyard wintry...  Negative  \n",
       "1  maybe aged eight exceptionally dim-witted may ...  Negative  \n",
       "2           slab market research search actual movie  Negative  \n",
       "3  they'd played laughs might worked fact earnest...  Negative  \n",
       "4  ineffably wooden chris columbus adaptation aut...  Negative  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#seperate from reviews and response\n",
    "\n",
    "X = df['review_content']\n",
    "y = df['sentiment']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47229,)\n",
      "(47229,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11808,)\n",
      "(11808,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "tvec = TfidfVectorizer()\n",
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
       "                ('classifier', LogisticRegression())])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Pipeline([('vectorizer',tvec),('classifier',clf)])\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Positive', 'Negative', 'Negative', ..., 'Positive', 'Negative',\n",
       "       'Positive'], dtype=object)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8788109756097561\n",
      "[[2661 1128]\n",
      " [ 303 7716]]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,pred))\n",
    "print(confusion_matrix(y_test,pred))\n",
    "# We get an accuracy score of 87 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jakub/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jakub/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jakub/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jakub/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jakub/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jakub/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jakub/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jakub/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#perform crossvalidation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(model, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8750951269782898\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(scores)) # After performing a 10 k-fold cross validation we get an overall average score of 87% making it a consistent classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Positive', 'Negative'], dtype=object)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Try out a few random movie reviews to see how the model runs \n",
    "a = 'This is the best movie','This is a terrible move'\n",
    "model.predict(list(a))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aa8bf794e1f9325552d8708e15b53db3e39e8272ef09c511ea107ffd37124942"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
